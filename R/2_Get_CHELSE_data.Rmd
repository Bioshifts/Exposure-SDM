---
title: "Species redistribution - Get predictor variables for use in SDMs"
author: "Brunno F Oliveira"
date: Sys.Date()
output:   
  html_document:
    toc: true
    toc_float: true
    code_folding: hide 
---

# Download 
Data from Chelsa (https://chelsa-climate.org/downloads/)

Variables of interest following Vanderwal 2013 NatClimChange (mean, minimum, maximum and standard deviation of monthly temperature, sum and coefficient of variation of precipitation, and sum of wettest and driest quarter for precipitation):  
* Mean monthly daily air temperature >> tas  *
* Mean monthly minimum air temperature >> tasmin  * 
* Mean monthly maximum air temperature >> tasmax  * 
* Total monthly precipitation >> pr  * 

From these variables we will create these others variables by integrating over the last 24 month from species occurrence:
* Mean annual air temperature >> tas  *
* Mean annual minimum air temperature >> tasmin  * 
* Mean annual maximum air temperature >> tasmax  * 
* Temperature seasonality >> SD(tas)  * 
* Annual precipitation amount >> pr  * 
* Precipitation seasonality >> CV(pr)  * 
* Mean monthly precipitation amount of the wettest quarter >> The wettest quarter of the year is determined (to the nearest month)  * 
* Mean monthly precipitation amount of the driest quarter >> The driest quarter of the year is determined (to the nearest month)  * 

DO NOT PARALLELIZE THIS WORK! YOU ARE LIMITED BY NETWORK SPEED. IF PARALLELIZING YOU END UP WITH A LOT OF SLOW DOWNLOADS.

RUN THIS ON NEW SCREEN IN ROSSINANTE

```{r eval=FALSE}

ssh rossinante
# new screen
screen -S chelse
cd Exposure-SDM
R

### R-code ###

# Setup

rm(list=ls())
gc()

list.of.packages <- c("raster","spdep","rgdal","rworldmap","maptools","terra","ff",
                      "reshape2","tidyr","tidyverse",
                      "foreach","doParallel","pbapply")

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]

if(length(new.packages)) install.packages(new.packages)

sapply(list.of.packages, require, character.only = TRUE)

# increase default timeout (=60s) prevents downloads to stop before finishing
options(timeout=3000) 

# load functions
source(here::here("R/my_functions.R"))

t.period <- 1980:2019 # Limits of the Chelsa database
nc_path <- "/media/seagate/boliveira/Land"

periods <- format(
    seq.Date(from = as.Date("1980/1/1"), 
             to = as.Date("2019/12/1"), 
             by = "month"), 
    "%m_%Y")

vars <- c("tasmax", "tasmin", "tas", "pr")

for (v in 1:length(vars)){
    
    cat("/rDownloading", vars[v])
    
    pbsapply(periods, function(i) {
        
        getChelse(vars[v], i, 
                  here::here(nc_path,"raw"), # save to a raw folder because these rasters will to be cropped latter (remove ocean)
                  over.write = FALSE)
    })
}
names(vars.out) <- vars

########################################################################
# test if everything has been downloaded
my.test <- list()
for(i in 1:length(vars)){
    # Files should look  like this 
    myfiles <- paste0("CHELSA_",vars[i],"_",periods,"_V.2.1.tif")
    # N downloaded files
    mydowns <- list.files(here::here(nc_path,"raw",vars[i]), pattern = "*.tif")
    # test
    my.test[[i]] <- myfiles[which(!myfiles %in% mydowns)]
}
names(my.test) <- vars
my.test

#######
## There are missing variables for precipitation from CHELSE at these dates: 
## "07_2019" "08_2019" "09_2019" "10_2019" "11_2019" "12_2019"
#######

# Rerun if any FALSE
# detect what is left
if(any(sapply(my.test, length)>0)){
    togovar <- which(sapply(my.test, length)>0)
    togovar <- my.test[togovar]
    togovars <- names(togovar)
    
    varstogo <- lapply(togovar, function(x) strsplit(x, "_"))
    varstogo <- lapply(varstogo, function(x) sapply(x, function(y) paste(y[3], y[4], sep = "_")))
    
    for (v in 1:length(togovars)){
        
        cat("/rDownloading", togovars[v])
        
        pbsapply(varstogo, function(i) {
            
            getChelse(togovars[v], i, here::here(nc_path,"raw"), over.write = FALSE)
            
        })
    }
}

########################################################################

# Test for potential errors when downloading variables
# Check if Download size from the server match file download sizes

# Get my file sizes
myfilesize <- list()
for(i in 1:length(vars)){ cat("\r",vars[i])
    myfiles <- list.files(here::here(nc_path,"raw",vars[i]), 
                          full.names = TRUE)
    # Get my file size
    myfilesize. <- sapply(myfiles, function(x) file.info(x)$size)
    # name
    name. <- sapply(myfiles, function(x){
        tmp. <- strsplit(x,"_")[[1]]
        paste(tmp.[3],tmp.[4],sep = "_")
    })
    names(myfilesize.) <- name.
    myfilesize[[i]] <- data.frame(file = names(myfilesize.), size = myfilesize.)
}
names(myfilesize) <- vars

# get server file size
serverfilesize <- list()
for(i in 1:length(vars)){ cat(vars[i],"\n")
    
    serverfilesize. <- pbsapply(myfilesize[[vars[i]]]$file, function(x) DownloadSizeChelse(vars[i], x))
    serverfilesize[[i]] <- data.frame(file = names(serverfilesize.), size = serverfilesize.)
}
names(serverfilesize) <- vars

sapply(myfilesize, dim)
sapply(serverfilesize, dim)

# merge
mergesizes <- lapply(vars, function(x) merge(myfilesize[[x]], serverfilesize[[x]], by = "file", all = TRUE))
names(mergesizes) <- vars
sapply(mergesizes, dim)

# check mismatch in size
misSize <- lapply(vars, function(x){
    mergesizes[[x]][,1][which(!mergesizes[[x]][,2] == mergesizes[[x]][,3])]
})
names(misSize) <- vars
misSize

# Rerun if any FALSE
# detect files sizes smaller than threshold
if(!all(sapply(misSize, length)==0)){
    
    varstogo <- names(misSize)[which(!sapply(misSize, length)==0)]
    
    options(timeout=3000) # prevents downloads to not finish due to default timeout (=60s)
    
    for (v in 1:length(varstogo)){
        
        periodstogo <- misSize[[varstogo[v]]]
        
        cat("/rDownloading", varstogo[v])
        
        try(pbsapply(periodstogo, function(i) {
            
            getChelse(varstogo[v], i, 
                      here::here(nc_path,"raw"), 
                      over.write = TRUE)
            
        }), silent = TRUE)
    }
}

```

# Crop land
```{r}

# load land
land.shp <- speciesgeocodeR::landmass
land.shp <- vect(land.shp)

# load one raster
myrast <- rast(list.files(here::here(nc_path,"raw",vars[1]),
                          full.names = TRUE)[2])
mymask <- terra::mask(myrast, land.shp)

# detect NA cells
cellsNA <- which(is.na(mymask[]))
# myrast2 <- myrast
# myrast2[cellsNA] <- NA
# plot(myrast2)
# plot(myrast)

for (v in 1:length(vars)){
    
    cat("Masking", vars[v], "\n")
    
    myfiles <- list.files(here::here(nc_path,"raw",vars[v]),
                          full.names = TRUE)
    
    new.dir <- here::here(nc_path,vars[v])
    if(!dir.exists(new.dir)){
        dir.create(new.dir,recursive = T)
    }
    
    tosave <- here::here(new.dir,
                         list.files(here::here(nc_path,vars[v])))
    
    cl <- makeCluster(5) # uses lots of memory so be wise here!
    clusterExport(cl, c("myfiles", "cellsNA", "tosave", "nc_path", "vars", "v"))
    
    pbsapply(1:length(myfiles), FUN = function(i){
        
        # check if file exists
        if(!file.exists(tosave[i])){
            myfile.tmp <- terra::rast(myfiles[i])
            # Mask
            myfile.tmp[cellsNA] <- NA
            
            terra::writeRaster(x = myfile.tmp, 
                               filename = tosave[i],
                               overwrite=TRUE)
            
            gc()
        }
    },
    cl = cl)
    
    stopCluster(cl)
    
}


```

# Save model raster
To be used for extracting cell ID
```{r}

tmp <- rast(tosave[10])
m <- c(minmax(tmp), 1)
rclmat <- matrix(m, ncol=3, byrow=TRUE)
rc1 <- terra::classify(tmp, rclmat, include.lowest=TRUE, othersNA = TRUE)

writeRaster(rc1, 
            here::here(nc_path,"model_raster_ter.tif"), 
            overwrite = TRUE)

```

